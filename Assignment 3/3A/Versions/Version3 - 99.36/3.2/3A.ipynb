{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Add, Input\n",
    "from keras.layers import Conv2D,MaxPooling2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 60000\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train),(X_test, Y_test) = mnist.load_data()\n",
    "print(len(X_train), len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_X, augmented_Y = [], []\n",
    "\n",
    "blurer = iaa.GaussianBlur(3.0)\n",
    "noise = iaa.AdditiveGaussianNoise(scale=0.1*255)\n",
    "coarse_dropout = iaa.CoarseDropout(p=0.2, size_percent=0.05)\n",
    "\n",
    "for image,label in zip(X_train, Y_train):\n",
    "    augmented_X.append(image)\n",
    "    augmented_Y.append(label)\n",
    "    \n",
    "    augmented_X.append(noise.augment_image(image))\n",
    "    augmented_Y.append(label)\n",
    "\n",
    "    augmented_X.append(coarse_dropout.augment_image(image))\n",
    "    augmented_Y.append(label)\n",
    "\n",
    "    augmented_X.append(cv2.GaussianBlur(image,(3,3),3))\n",
    "    augmented_Y.append(label)\n",
    "    \n",
    "    augmented_X.append(cv2.equalizeHist(image))\n",
    "    augmented_Y.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000 300000\n"
     ]
    }
   ],
   "source": [
    "# Convert Images and Steering values to numpy arrays since keras requires them in that form\n",
    "X_train = np.array(augmented_X)\n",
    "Y_train = np.array(augmented_Y)\n",
    "print(len(X_train), len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 28, 28)\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18bd178afd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train[100])\n",
    "plt.imshow(X_train[100], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the Input:\n",
    "    We need to reshape the input as new Keras API expects us to mention the total color-channels as well (1 in our case as we have grayscale images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion and Normalization:\n",
    "All images are stored as unit8, however, we work with floats in neural network. So first thing we do is to convert our images from uint8 to float32. Then, we convert our images from 0-255 scale to 0-1. This is called normalization. We usually do this because:\n",
    "\n",
    "- 0-1 is easier to deal with.\n",
    "- keeping other variables within a range (0-1) becomes easier if inputs are also between (0-1).\n",
    "- keeping values between (0-1) also, sort of, adds an in-built threshold (0.9*0.9 = 0.81, but 229*229 = 52441)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "norm_1 (BatchNormalization)  (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "norm_2 (BatchNormalization)  (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 24, 24, 16)        528       \n",
      "_________________________________________________________________\n",
      "norm_3 (BatchNormalization)  (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 10, 10, 32)        4640      \n",
      "_________________________________________________________________\n",
      "norm_4 (BatchNormalization)  (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 10, 10, 16)        528       \n",
      "_________________________________________________________________\n",
      "norm_5 (BatchNormalization)  (None, 10, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 8, 8, 10)          1450      \n",
      "_________________________________________________________________\n",
      "norm_6 (BatchNormalization)  (None, 8, 8, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 6, 6, 10)          910       \n",
      "_________________________________________________________________\n",
      "norm_7 (BatchNormalization)  (None, 6, 6, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv_8 (Conv2D)              (None, 6, 6, 10)          110       \n",
      "_________________________________________________________________\n",
      "norm_8 (BatchNormalization)  (None, 6, 6, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv_9 (Conv2D)              (None, 1, 1, 10)          910       \n",
      "_________________________________________________________________\n",
      "norm_9 (BatchNormalization)  (None, 1, 1, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 19,426\n",
      "Trainable params: 19,090\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28, 28, 1,))\n",
    "\n",
    "# Layer 1: Input => [28x28x1]     Output => [26x26x32]\n",
    "layer1 = Conv2D(32, (3,3), name='conv_1')(input1)\n",
    "layer1 = BatchNormalization(name='norm_1')(layer1)\n",
    "layer1 = Activation('relu')(layer1) \n",
    "layer1 = Dropout(0.1)(layer1)\n",
    "\n",
    "# Layer 2: Input => [26x26x32]     Output => [24x24x32]\n",
    "layer2 = Conv2D(32, (3,3), name='conv_2')(layer1)\n",
    "layer2 = BatchNormalization(name='norm_2')(layer2)\n",
    "layer2 = Activation('relu')(layer2)\n",
    "layer2 = Dropout(0.1)(layer2)\n",
    "\n",
    "# Layer 3: Input => [24x24x32]     Output => [12x12x16]\n",
    "layer3 = Conv2D(16, (1,1), name='conv_3')(layer2)\n",
    "layer3 = BatchNormalization(name='norm_3')(layer3)\n",
    "layer3 = Activation('relu')(layer3)\n",
    "layer3 = MaxPooling2D(pool_size=(2, 2))(layer3)\n",
    "\n",
    "# Layer 4: Input => [12x12x16]     Output => [10x10x32]\n",
    "layer4 = Conv2D(32, (3,3), name='conv_4')(layer3)\n",
    "layer4 = BatchNormalization(name='norm_4')(layer4)\n",
    "layer4 = Activation('relu')(layer4)\n",
    "layer4 = Dropout(0.1)(layer4)\n",
    "\n",
    "# Layer 5: Input => [10x10x32]     Output => [10x10x16]\n",
    "layer5 = Conv2D(16, (1,1), name='conv_5')(layer4)\n",
    "layer5 = BatchNormalization(name='norm_5')(layer5)\n",
    "layer5 = Activation('relu')(layer5)\n",
    "layer5 = Dropout(0.1)(layer5)\n",
    "\n",
    "# Layer 6: Input => [10x10x16]     Output => [8x8x10]\n",
    "layer6 = Conv2D(10, (3,3), name='conv_6')(layer5)\n",
    "layer6 = BatchNormalization(name='norm_6')(layer6)\n",
    "layer6 = Activation('relu')(layer6)\n",
    "layer6 = Dropout(0.1)(layer6)\n",
    "\n",
    "# Layer 7: Input => [8x8x10]     Output => [6x6x10]\n",
    "layer7 = Conv2D(10, (3,3), name='conv_7')(layer6)\n",
    "layer7 = BatchNormalization(name='norm_7')(layer7)\n",
    "layer7 = Activation('relu')(layer7)\n",
    "layer7 = Dropout(0.1)(layer7)\n",
    "\n",
    "# Layer 8: Input => [6x6x10]     Output => [3x3x10]\n",
    "layer8 = Conv2D(10, (1,1), name='conv_8')(layer7)\n",
    "layer8 = BatchNormalization(name='norm_8')(layer8)\n",
    "layer8 = Activation('relu')(layer8)\n",
    "layer8 = MaxPooling2D(pool_size=(2, 2))(layer8)\n",
    "\n",
    "# Layer 9: Input => [3x3x10]     Output => [1x1x10]\n",
    "layer9 = Conv2D(10, (3,3), name='conv_9')(layer8)\n",
    "layer9 = BatchNormalization(name='norm_9')(layer9)\n",
    "layer9 = Activation('relu')(layer9)\n",
    "\n",
    "# Layer 10\n",
    "layer10 = Flatten()(layer9)\n",
    "output = Dense(num_classes, activation='softmax')(layer10)\n",
    "\n",
    "model = Model(inputs=[input1], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "300000/300000 [==============================] - 84s 279us/step - loss: 0.5537 - acc: 0.8471\n",
      "Epoch 2/50\n",
      "300000/300000 [==============================] - 83s 278us/step - loss: 0.1668 - acc: 0.9501\n",
      "Epoch 3/50\n",
      "300000/300000 [==============================] - 87s 291us/step - loss: 0.1303 - acc: 0.9594\n",
      "Epoch 4/50\n",
      "300000/300000 [==============================] - 87s 290us/step - loss: 0.1124 - acc: 0.9648\n",
      "Epoch 5/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.1002 - acc: 0.9685\n",
      "Epoch 6/50\n",
      "300000/300000 [==============================] - 87s 290us/step - loss: 0.0936 - acc: 0.9704\n",
      "Epoch 7/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0880 - acc: 0.9722\n",
      "Epoch 8/50\n",
      "300000/300000 [==============================] - 87s 290us/step - loss: 0.0832 - acc: 0.9733\n",
      "Epoch 9/50\n",
      "300000/300000 [==============================] - 87s 290us/step - loss: 0.0794 - acc: 0.9748\n",
      "Epoch 10/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0765 - acc: 0.9755\n",
      "Epoch 11/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0733 - acc: 0.9766\n",
      "Epoch 12/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0710 - acc: 0.9774\n",
      "Epoch 13/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0695 - acc: 0.9777\n",
      "Epoch 14/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0686 - acc: 0.97810s - loss: 0.0685 - acc\n",
      "Epoch 15/50\n",
      "300000/300000 [==============================] - 87s 290us/step - loss: 0.0670 - acc: 0.9783\n",
      "Epoch 16/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0650 - acc: 0.9792\n",
      "Epoch 17/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0630 - acc: 0.9796\n",
      "Epoch 18/50\n",
      "300000/300000 [==============================] - 87s 290us/step - loss: 0.0619 - acc: 0.9799\n",
      "Epoch 19/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0608 - acc: 0.9805\n",
      "Epoch 20/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0593 - acc: 0.9811\n",
      "Epoch 21/50\n",
      "300000/300000 [==============================] - 87s 290us/step - loss: 0.0596 - acc: 0.9807\n",
      "Epoch 22/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0580 - acc: 0.9811\n",
      "Epoch 23/50\n",
      "300000/300000 [==============================] - 87s 290us/step - loss: 0.0559 - acc: 0.9818\n",
      "Epoch 24/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0562 - acc: 0.9819\n",
      "Epoch 25/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0555 - acc: 0.9821\n",
      "Epoch 26/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0552 - acc: 0.9821\n",
      "Epoch 27/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0551 - acc: 0.9823\n",
      "Epoch 28/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0538 - acc: 0.9826\n",
      "Epoch 29/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0528 - acc: 0.9829\n",
      "Epoch 30/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0520 - acc: 0.9832\n",
      "Epoch 31/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0514 - acc: 0.9836\n",
      "Epoch 32/50\n",
      "300000/300000 [==============================] - 86s 287us/step - loss: 0.0513 - acc: 0.9835\n",
      "Epoch 33/50\n",
      "300000/300000 [==============================] - 86s 287us/step - loss: 0.0505 - acc: 0.9837\n",
      "Epoch 34/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0508 - acc: 0.9837\n",
      "Epoch 35/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0498 - acc: 0.9838\n",
      "Epoch 36/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0493 - acc: 0.9841\n",
      "Epoch 37/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0488 - acc: 0.9843\n",
      "Epoch 38/50\n",
      "300000/300000 [==============================] - 87s 288us/step - loss: 0.0483 - acc: 0.9845\n",
      "Epoch 39/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0482 - acc: 0.9842\n",
      "Epoch 40/50\n",
      "300000/300000 [==============================] - 86s 287us/step - loss: 0.0481 - acc: 0.9842\n",
      "Epoch 41/50\n",
      "300000/300000 [==============================] - 87s 291us/step - loss: 0.0485 - acc: 0.9845\n",
      "Epoch 42/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0467 - acc: 0.9848\n",
      "Epoch 43/50\n",
      "300000/300000 [==============================] - 86s 287us/step - loss: 0.0474 - acc: 0.9846\n",
      "Epoch 44/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0474 - acc: 0.9847\n",
      "Epoch 45/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0466 - acc: 0.9847\n",
      "Epoch 46/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0452 - acc: 0.9852\n",
      "Epoch 47/50\n",
      "300000/300000 [==============================] - 86s 288us/step - loss: 0.0455 - acc: 0.9850\n",
      "Epoch 48/50\n",
      "300000/300000 [==============================] - 86s 287us/step - loss: 0.0456 - acc: 0.9851\n",
      "Epoch 49/50\n",
      "300000/300000 [==============================] - 87s 289us/step - loss: 0.0445 - acc: 0.9856\n",
      "Epoch 50/50\n",
      "300000/300000 [==============================] - 86s 287us/step - loss: 0.0443 - acc: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18bd17f5668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.36 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2475189e-05 2.3538649e-05 9.9987519e-01 1.1500372e-06 1.1634226e-06\n",
      " 1.8158968e-08 3.4824247e-05 6.2463293e-08 3.1438529e-05 1.5922950e-08]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18c17f48438>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# manual test\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred[1])\n",
    "print(y_test[1])\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28)\n",
    "X_test *= 255\n",
    "%matplotlib inline\n",
    "plt.imshow(X_test[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('version3_copy.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
