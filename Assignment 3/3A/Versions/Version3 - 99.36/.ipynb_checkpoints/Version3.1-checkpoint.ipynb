{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Add, Input\n",
    "from keras.layers import Conv2D,MaxPooling2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 60000\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train),(X_test, Y_test) = mnist.load_data()\n",
    "print(len(X_train), len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_X, augmented_Y = [], []\n",
    "\n",
    "blurer = iaa.GaussianBlur(3.0)\n",
    "noise = iaa.AdditiveGaussianNoise(scale=0.1*255)\n",
    "coarse_dropout = iaa.CoarseDropout(p=0.2, size_percent=0.05)\n",
    "\n",
    "for image,label in zip(X_train, Y_train):\n",
    "    augmented_X.append(image)\n",
    "    augmented_Y.append(label)\n",
    "    \n",
    "#     augmented_X.append(noise.augment_image(image))\n",
    "#     augmented_Y.append(label)\n",
    "\n",
    "    augmented_X.append(coarse_dropout.augment_image(image))\n",
    "    augmented_Y.append(label)\n",
    "\n",
    "    augmented_X.append(cv2.GaussianBlur(image,(3,3),3))\n",
    "    augmented_Y.append(label)\n",
    "    \n",
    "    augmented_X.append(cv2.equalizeHist(image))\n",
    "    augmented_Y.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000 240000\n"
     ]
    }
   ],
   "source": [
    "# Convert Images and Steering values to numpy arrays since keras requires them in that form\n",
    "X_train = np.array(augmented_X)\n",
    "Y_train = np.array(augmented_Y)\n",
    "print(len(X_train), len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 28, 28)\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17031d89f60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train[100])\n",
    "plt.imshow(X_train[100], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the Input:\n",
    "    We need to reshape the input as new Keras API expects us to mention the total color-channels as well (1 in our case as we have grayscale images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion and Normalization:\n",
    "All images are stored as unit8, however, we work with floats in neural network. So first thing we do is to convert our images from uint8 to float32. Then, we convert our images from 0-255 scale to 0-1. This is called normalization. We usually do this because:\n",
    "\n",
    "- 0-1 is easier to deal with.\n",
    "- keeping other variables within a range (0-1) becomes easier if inputs are also between (0-1).\n",
    "- keeping values between (0-1) also, sort of, adds an in-built threshold (0.9*0.9 = 0.81, but 229*229 = 52441)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "norm_1 (BatchNormalization)  (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "norm_2 (BatchNormalization)  (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 24, 24, 16)        528       \n",
      "_________________________________________________________________\n",
      "norm_3 (BatchNormalization)  (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 10, 10, 32)        4640      \n",
      "_________________________________________________________________\n",
      "norm_4 (BatchNormalization)  (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 10, 10, 16)        528       \n",
      "_________________________________________________________________\n",
      "norm_5 (BatchNormalization)  (None, 10, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 8, 8, 10)          1450      \n",
      "_________________________________________________________________\n",
      "norm_6 (BatchNormalization)  (None, 8, 8, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 8, 8, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8, 8, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 6, 6, 10)          910       \n",
      "_________________________________________________________________\n",
      "norm_7 (BatchNormalization)  (None, 6, 6, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv_8 (Conv2D)              (None, 6, 6, 10)          110       \n",
      "_________________________________________________________________\n",
      "norm_8 (BatchNormalization)  (None, 6, 6, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv_9 (Conv2D)              (None, 1, 1, 10)          910       \n",
      "_________________________________________________________________\n",
      "norm_9 (BatchNormalization)  (None, 1, 1, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 19,426\n",
      "Trainable params: 19,090\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28, 28, 1,))\n",
    "\n",
    "# Layer 1: Input => [28x28x1]     Output => [26x26x32]\n",
    "layer1 = Conv2D(32, (3,3), name='conv_1')(input1)\n",
    "layer1 = BatchNormalization(name='norm_1')(layer1)\n",
    "layer1 = Activation('relu')(layer1) \n",
    "layer1 = Dropout(0.1)(layer1)\n",
    "\n",
    "# Layer 2: Input => [26x26x32]     Output => [24x24x32]\n",
    "layer2 = Conv2D(32, (3,3), name='conv_2')(layer1)\n",
    "layer2 = BatchNormalization(name='norm_2')(layer2)\n",
    "layer2 = Activation('relu')(layer2)\n",
    "layer2 = Dropout(0.1)(layer2)\n",
    "\n",
    "# Layer 3: Input => [24x24x32]     Output => [12x12x16]\n",
    "layer3 = Conv2D(16, (1,1), name='conv_3')(layer2)\n",
    "layer3 = BatchNormalization(name='norm_3')(layer3)\n",
    "layer3 = Activation('relu')(layer3)\n",
    "layer3 = MaxPooling2D(pool_size=(2, 2))(layer3)\n",
    "\n",
    "# Layer 4: Input => [12x12x16]     Output => [10x10x32]\n",
    "layer4 = Conv2D(32, (3,3), name='conv_4')(layer3)\n",
    "layer4 = BatchNormalization(name='norm_4')(layer4)\n",
    "layer4 = Activation('relu')(layer4)\n",
    "layer4 = Dropout(0.1)(layer4)\n",
    "\n",
    "# Layer 5: Input => [10x10x32]     Output => [10x10x16]\n",
    "layer5 = Conv2D(16, (1,1), name='conv_5')(layer4)\n",
    "layer5 = BatchNormalization(name='norm_5')(layer5)\n",
    "layer5 = Activation('relu')(layer5)\n",
    "layer5 = Dropout(0.1)(layer5)\n",
    "\n",
    "# Layer 6: Input => [10x10x16]     Output => [8x8x10]\n",
    "layer6 = Conv2D(10, (3,3), name='conv_6')(layer5)\n",
    "layer6 = BatchNormalization(name='norm_6')(layer6)\n",
    "layer6 = Activation('relu')(layer6)\n",
    "layer6 = Dropout(0.1)(layer6)\n",
    "\n",
    "# Layer 7: Input => [8x8x10]     Output => [6x6x10]\n",
    "layer7 = Conv2D(10, (3,3), name='conv_7')(layer6)\n",
    "layer7 = BatchNormalization(name='norm_7')(layer7)\n",
    "layer7 = Activation('relu')(layer7)\n",
    "layer7 = Dropout(0.1)(layer7)\n",
    "\n",
    "# Layer 8: Input => [6x6x10]     Output => [3x3x10]\n",
    "layer8 = Conv2D(10, (1,1), name='conv_8')(layer7)\n",
    "layer8 = BatchNormalization(name='norm_8')(layer8)\n",
    "layer8 = Activation('relu')(layer8)\n",
    "layer8 = MaxPooling2D(pool_size=(2, 2))(layer8)\n",
    "\n",
    "# Layer 9: Input => [3x3x10]     Output => [1x1x10]\n",
    "layer9 = Conv2D(10, (3,3), name='conv_9')(layer8)\n",
    "layer9 = BatchNormalization(name='norm_9')(layer9)\n",
    "layer9 = Activation('relu')(layer9)\n",
    "\n",
    "# Layer 10\n",
    "layer10 = Flatten()(layer9)\n",
    "output = Dense(num_classes, activation='softmax')(layer10)\n",
    "\n",
    "model = Model(inputs=[input1], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "240000/240000 [==============================] - 67s 279us/step - loss: 0.6492 - acc: 0.8174\n",
      "Epoch 2/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.2040 - acc: 0.93820s - loss: 0.2044 \n",
      "Epoch 3/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.1564 - acc: 0.9511\n",
      "Epoch 4/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.1352 - acc: 0.9574\n",
      "Epoch 5/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.1220 - acc: 0.9614\n",
      "Epoch 6/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.1139 - acc: 0.9632\n",
      "Epoch 7/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.1070 - acc: 0.9663\n",
      "Epoch 8/30\n",
      "240000/240000 [==============================] - 70s 291us/step - loss: 0.1018 - acc: 0.9675\n",
      "Epoch 9/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.0963 - acc: 0.9696\n",
      "Epoch 10/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.0928 - acc: 0.9706\n",
      "Epoch 11/30\n",
      "240000/240000 [==============================] - 70s 291us/step - loss: 0.0894 - acc: 0.9714\n",
      "Epoch 12/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.0865 - acc: 0.9721\n",
      "Epoch 13/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.0856 - acc: 0.9722\n",
      "Epoch 14/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.0829 - acc: 0.9739\n",
      "Epoch 15/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.0800 - acc: 0.9744\n",
      "Epoch 16/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.0785 - acc: 0.9746\n",
      "Epoch 17/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.0768 - acc: 0.9753\n",
      "Epoch 18/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.0747 - acc: 0.9761\n",
      "Epoch 19/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.0733 - acc: 0.9766\n",
      "Epoch 20/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.0718 - acc: 0.9769\n",
      "Epoch 21/30\n",
      "240000/240000 [==============================] - 71s 294us/step - loss: 0.0712 - acc: 0.9771\n",
      "Epoch 22/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.0697 - acc: 0.9776\n",
      "Epoch 23/30\n",
      "240000/240000 [==============================] - 70s 294us/step - loss: 0.0687 - acc: 0.9777\n",
      "Epoch 24/30\n",
      "240000/240000 [==============================] - 71s 294us/step - loss: 0.0666 - acc: 0.9786\n",
      "Epoch 25/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.0663 - acc: 0.9787\n",
      "Epoch 26/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.0654 - acc: 0.9787\n",
      "Epoch 27/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.0649 - acc: 0.9790\n",
      "Epoch 28/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.0630 - acc: 0.9797\n",
      "Epoch 29/30\n",
      "240000/240000 [==============================] - 70s 292us/step - loss: 0.0629 - acc: 0.9796\n",
      "Epoch 30/30\n",
      "240000/240000 [==============================] - 70s 293us/step - loss: 0.0637 - acc: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x171a1036f60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.27 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.02931845e-05 9.77050368e-05 9.99701798e-01 4.53209068e-05\n",
      " 7.96402855e-06 6.02067246e-07 2.88197157e-06 3.73096395e-06\n",
      " 1.26705039e-04 3.05034132e-06]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x171d4285eb8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# manual test\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred[1])\n",
    "print(y_test[1])\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28)\n",
    "X_test *= 255\n",
    "%matplotlib inline\n",
    "plt.imshow(X_test[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('version3.1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
