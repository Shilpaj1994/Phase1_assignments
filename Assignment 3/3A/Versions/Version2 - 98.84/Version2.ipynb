{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Add, Input\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Conv2D,MaxPooling2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 60000\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train),(X_test, Y_test) = mnist.load_data()\n",
    "print(len(X_train), len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_X, augmented_Y = [], []\n",
    "\n",
    "blurer = iaa.GaussianBlur(3.0)\n",
    "noise = iaa.AdditiveGaussianNoise(scale=0.1*255)\n",
    "coarse_dropout = iaa.CoarseDropout(p=0.2, size_percent=0.05)\n",
    "\n",
    "for image,label in zip(X_train, Y_train):\n",
    "    augmented_X.append(image)\n",
    "    augmented_Y.append(label)\n",
    "    \n",
    "    augmented_X.append(noise.augment_image(image))\n",
    "    augmented_Y.append(label)\n",
    "\n",
    "    augmented_X.append(coarse_dropout.augment_image(image))\n",
    "    augmented_Y.append(label)\n",
    "\n",
    "    augmented_X.append(cv2.GaussianBlur(image,(3,3),3))\n",
    "    augmented_Y.append(label)\n",
    "    \n",
    "    augmented_X.append(cv2.equalizeHist(image))\n",
    "    augmented_Y.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000 240000\n"
     ]
    }
   ],
   "source": [
    "# Convert Images and Steering values to numpy arrays since keras requires them in that form\n",
    "X_train = np.array(augmented_X)\n",
    "Y_train = np.array(augmented_Y)\n",
    "print(len(X_train), len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 28, 28)\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a86b4750b8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train[60000-1])\n",
    "# print(X_train.shape)\n",
    "plt.imshow(X_train[60000-1], cmap='gray')\n",
    "# plt.imshow(X_train[120000-1], cmap='gray')\n",
    "# plt.imshow(X_train[180000-1], cmap='gray')\n",
    "# plt.imshow(X_train[240000-1], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the Input:\n",
    "    We need to reshape the input as new Keras API expects us to mention the total color-channels as well (1 in our case as we have grayscale images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "# print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion and Normalization:\n",
    "All images are stored as unit8, however, we work with floats in neural network. So first thing we do is to convert our images from uint8 to float32. Then, we convert our images from 0-255 scale to 0-1. This is called normalization. We usually do this because:\n",
    "\n",
    "- 0-1 is easier to deal with.\n",
    "- keeping other variables within a range (0-1) becomes easier if inputs are also between (0-1).\n",
    "- keeping values between (0-1) also, sort of, adds an in-built threshold (0.9*0.9 = 0.81, but 229*229 = 52441)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "norm_1 (BatchNormalization)  (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "norm_2 (BatchNormalization)  (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 24, 24, 32)        1056      \n",
      "_________________________________________________________________\n",
      "norm_3 (BatchNormalization)  (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 10, 10, 16)        4624      \n",
      "_________________________________________________________________\n",
      "norm_4 (BatchNormalization)  (None, 10, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 10, 10, 16)        272       \n",
      "_________________________________________________________________\n",
      "norm_5 (BatchNormalization)  (None, 10, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 8, 8, 10)          1450      \n",
      "_________________________________________________________________\n",
      "norm_6 (BatchNormalization)  (None, 8, 8, 10)          40        \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 8, 8, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 6, 6, 10)          910       \n",
      "_________________________________________________________________\n",
      "norm_7 (BatchNormalization)  (None, 6, 6, 10)          40        \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 3, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv_8 (Conv2D)              (None, 1, 1, 10)          910       \n",
      "_________________________________________________________________\n",
      "norm_8 (BatchNormalization)  (None, 1, 1, 10)          40        \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 19,532\n",
      "Trainable params: 19,216\n",
      "Non-trainable params: 316\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28, 28, 1,))\n",
    "\n",
    "# Layer 1: Input => [28x28x1],1\n",
    "#          Output => [26x26x**],**\n",
    "layer1 = Conv2D(32, (3,3), name='conv_1')(input1)\n",
    "layer1 = BatchNormalization(name='norm_1')(layer1)\n",
    "layer1 = Activation('relu')(layer1)\n",
    "layer1 = Dropout(0.2)(layer1)\n",
    "\n",
    "# Layer 2: Input => [26x26x**],**\n",
    "#          Output => [24x24x**],**\n",
    "layer2 = Conv2D(32, (3,3), name='conv_2')(layer1)\n",
    "layer2 = BatchNormalization(name='norm_2')(layer2)\n",
    "layer2 = Activation('relu')(layer2)\n",
    "layer2 = Dropout(0.2)(layer2)\n",
    "\n",
    "# Layer 3: Input => [24x24x**],**\n",
    "#          Output => [12x12x**],**\n",
    "layer3 = Conv2D(32, (1,1), name='conv_3')(layer2)\n",
    "layer3 = BatchNormalization(name='norm_3')(layer3)\n",
    "layer3 = Dropout(0.2)(layer3)\n",
    "layer3 = MaxPooling2D(pool_size=(2, 2))(layer3)\n",
    "\n",
    "# Layer 4: Input => [12x12x**],**\n",
    "#          Output => [10x10x**],**\n",
    "layer4 = Conv2D(16, (3,3), name='conv_4')(layer3)\n",
    "layer4 = BatchNormalization(name='norm_4')(layer4)\n",
    "layer4 = Dropout(0.2)(layer4)\n",
    "\n",
    "# Layer 5: Input => [10x10x**],**\n",
    "#          Output => [10x10x**],**\n",
    "layer5 = Conv2D(16, (1,1), name='conv_5')(layer4)\n",
    "layer5 = BatchNormalization(name='norm_5')(layer5)\n",
    "layer5 = Activation('relu')(layer5)\n",
    "layer5 = Dropout(0.2)(layer5)\n",
    "\n",
    "# Layer 6: Input => [10x10x**],**\n",
    "#          Output => [8x8x**],**\n",
    "layer6 = Conv2D(10, (3,3), name='conv_6')(layer5)\n",
    "layer6 = BatchNormalization(name='norm_6')(layer6)\n",
    "layer6 = Dropout(0.2)(layer6)\n",
    "\n",
    "# Layer 7: Input => [8x8x**],**\n",
    "#          Output => [3x3x**],**\n",
    "layer7 = Conv2D(10, (3,3), name='conv_7')(layer6)\n",
    "layer7 = BatchNormalization(name='norm_7')(layer7)\n",
    "layer7 = Dropout(0.2)(layer7)\n",
    "layer7 = MaxPooling2D(pool_size=(2, 2))(layer7)\n",
    "\n",
    "# Layer 8: Input => [3x3x**],**\n",
    "#          Output => [1x1x**],**\n",
    "layer8 = Conv2D(10, (3,3), name='conv_8')(layer7)\n",
    "layer8 = BatchNormalization(name='norm_8')(layer8)\n",
    "layer8 = Dropout(0.2)(layer8)\n",
    "\n",
    "# Layer 9\n",
    "layer9 = Flatten()(layer8)\n",
    "output = Dense(num_classes, activation='softmax')(layer9)\n",
    "\n",
    "model = Model(inputs=[input1], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "240000/240000 [==============================] - 68s 281us/step - loss: 0.6800 - acc: 0.7903\n",
      "Epoch 2/30\n",
      "240000/240000 [==============================] - 68s 284us/step - loss: 0.3457 - acc: 0.8900\n",
      "Epoch 3/30\n",
      "240000/240000 [==============================] - 69s 289us/step - loss: 0.2838 - acc: 0.9090\n",
      "Epoch 4/30\n",
      "240000/240000 [==============================] - 69s 288us/step - loss: 0.2504 - acc: 0.9206\n",
      "Epoch 5/30\n",
      "240000/240000 [==============================] - 69s 287us/step - loss: 0.2294 - acc: 0.9270\n",
      "Epoch 6/30\n",
      "240000/240000 [==============================] - 69s 286us/step - loss: 0.2141 - acc: 0.9323\n",
      "Epoch 7/30\n",
      "240000/240000 [==============================] - 69s 287us/step - loss: 0.2044 - acc: 0.9357\n",
      "Epoch 8/30\n",
      "240000/240000 [==============================] - 69s 286us/step - loss: 0.1935 - acc: 0.9382\n",
      "Epoch 9/30\n",
      "240000/240000 [==============================] - 69s 286us/step - loss: 0.1869 - acc: 0.9409\n",
      "Epoch 10/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1809 - acc: 0.9428\n",
      "Epoch 11/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1763 - acc: 0.9443\n",
      "Epoch 12/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1691 - acc: 0.9468\n",
      "Epoch 13/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1662 - acc: 0.9478\n",
      "Epoch 14/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1634 - acc: 0.9481\n",
      "Epoch 15/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1593 - acc: 0.9497\n",
      "Epoch 16/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1555 - acc: 0.9508\n",
      "Epoch 17/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1543 - acc: 0.9515\n",
      "Epoch 18/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1525 - acc: 0.9519\n",
      "Epoch 19/30\n",
      "240000/240000 [==============================] - 69s 285us/step - loss: 0.1494 - acc: 0.9534\n",
      "Epoch 20/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1481 - acc: 0.9535\n",
      "Epoch 21/30\n",
      "240000/240000 [==============================] - 69s 286us/step - loss: 0.1481 - acc: 0.9533\n",
      "Epoch 22/30\n",
      "240000/240000 [==============================] - 69s 286us/step - loss: 0.1463 - acc: 0.9541\n",
      "Epoch 23/30\n",
      "240000/240000 [==============================] - 69s 286us/step - loss: 0.1441 - acc: 0.9546\n",
      "Epoch 24/30\n",
      "240000/240000 [==============================] - 69s 285us/step - loss: 0.1429 - acc: 0.9556\n",
      "Epoch 25/30\n",
      "240000/240000 [==============================] - 69s 286us/step - loss: 0.1405 - acc: 0.9558\n",
      "Epoch 26/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1375 - acc: 0.9564\n",
      "Epoch 27/30\n",
      "240000/240000 [==============================] - 69s 286us/step - loss: 0.1373 - acc: 0.9569\n",
      "Epoch 28/30\n",
      "240000/240000 [==============================] - 69s 285us/step - loss: 0.1375 - acc: 0.9568\n",
      "Epoch 29/30\n",
      "240000/240000 [==============================] - 69s 285us/step - loss: 0.1370 - acc: 0.9569\n",
      "Epoch 30/30\n",
      "240000/240000 [==============================] - 68s 285us/step - loss: 0.1344 - acc: 0.9574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8418c3b70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.83999999999999 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.3624464e-04 2.0137848e-03 9.9753881e-01 4.4218341e-05 1.2840595e-06\n",
      " 1.6649578e-08 6.3711464e-05 1.4252525e-06 9.1663026e-08 3.8095584e-07]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a9dbd2be10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# manual test\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred[1])\n",
    "print(y_test[1])\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28)\n",
    "X_test *= 255\n",
    "%matplotlib inline\n",
    "plt.imshow(X_test[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('version2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
